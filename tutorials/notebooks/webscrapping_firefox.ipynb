{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Webscrapping with firefox\n",
    "This notebook serves to give an overview about how to download data via webscrapping and using firefox browser.\n",
    "   \n",
    "**Notes**:  \n",
    "- This notebook serves to explain the basics, yet it is not executable as selenium and jupyter are somehow not friends  \n",
    "\n",
    "- We still have the bug, that it resets all firefox settings when running the file. If your main browser is firefox, **!!! please don't use this code !!!** for now - I'm working on an update.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Set up\n",
    "a) To downlaod data via webscrapping we need to download a webdriver first. For firefox the webdriver is called 'geckodriver' and it can be downlaoded ath the bottom of the following page: https://github.com/mozilla/geckodriver/releases  \n",
    "Later in the code we will include the dir of the geckodriver and paste it as a str in path_geckodriver to the webscrape function\n",
    "  \n",
    "b) We also need to download the respective packages to be able to use Selenium (see imports from the code below).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Collecting the download links\n",
    "a) Once this is set up, we open firefox and go to the page with all the download links, such as https://geoportal.geoportal-th.de/gaialight-th/_apps/atomfeedexplorer/?#feed=http%3A//geoportal.geoportal-th.de/dienste/atom_th_gebaeude%3Ftype%3Ddataset%26id%3D97d152b8-9e00-49f3-9ae4-8bbb30873562 for Thueringen. \n",
    "Note that this page presents the download links in the atom feed explorer which uses java (which is the reason for why we use selenium).\n",
    "\n",
    "b) Afterwards we right click on the first link we want to download and select **'Inspect'**\n",
    "\n",
    "c) The developer mode of firefox will open and the respective field in the hmtl tree will be highlighted. \n",
    "\n",
    "d) right click on the highlighted part and select **'copy'** -> **'copy Xpath'** this is the xpath at of the first download file, which should be provided as a str in path_xpath1 to the webscrape function\n",
    "\n",
    "e) we do b,c,d again for the last file we want to downlod and provide the xpath as a str in path_xpath2 to the webscrape function\n",
    "\n",
    "d) runf the file with the setup as follows\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def webscrape(url_page,path_download_dir, path_geckodriver,path_xpath1, path_xpath2,sleep_time=5):\n",
    "    \"\"\"\n",
    "    Function to download files via webscrapping, using selenium and fireforx's \n",
    "    geckodriver, which can be downloaded here: https://github.com/mozilla/geckodriver/releases\n",
    "    \n",
    "    How to webscrape:\n",
    "    0. Download all required packages (incl. selenium and geckodriver)\n",
    "    1. Open the url with the download links in Firefox\n",
    "    2. right cklick on the first download link and select 'inspect'\n",
    "    3. right click again on the higlighted entry in firefox developer mode and choose 'copy path' -> 'xpath'\n",
    "    4. do the same for the last download link \n",
    "    \n",
    "    Args:\n",
    "    - url_page (str): address of webpage where files should be downloaded\n",
    "    - path_download_dir (str): path to dir in which downloads should be saved\n",
    "    - path_geckodriver (str): path to folder in which geckodriver is stored\n",
    "    - path_xpath1(str): xpath of file where download should start with\n",
    "    - path_xpath2 (str): xpath of file where download should stop (all download links in between will be downloaded)\n",
    "    - sleep_time (int): on some pages it takes some time to load all download links; here, a timer can be set to wait \n",
    "\n",
    "    Returns:\n",
    "    - \n",
    "\n",
    "    Last update: 21/06/21. By Felix.\n",
    "\n",
    "    \"\"\"\n",
    "    # intitialise download\n",
    "    print('Starting to download from '+url_page)\n",
    "    \n",
    "    # Set options for webdriver\n",
    "    options = FirefoxOptions()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    #options.headless = True\n",
    "\n",
    "    # in this case we set the options to avoid pop up windows when downloading\n",
    "    fp = webdriver.FirefoxProfile()\n",
    "\n",
    "    # Set 0 = desktop, 1 = default download folder, 2 = specified donwload folder\n",
    "    fp.set_preference(\"browser.download.folderList\", 2)\n",
    "    fp.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "\n",
    "    # Setting for specific download folder (downloadDir)\n",
    "    fp.set_preference(\"browser.download.dir\", path_download_dir)\n",
    "\n",
    "    # Setting to disable download pop up window and directly download file \n",
    "    fp.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/zip, application/octet-stream, multipart/x-zip, application/zip-compressed, application/x-zip-compressed\")\n",
    "\n",
    "    # Update preferences\n",
    "    fp.update_preferences()\n",
    "\n",
    "    #options.profile(fp)\n",
    "\n",
    "    # Run firefox webdriver from executable path of your choice\n",
    "    driver = webdriver.Firefox(firefox_profile = fp, executable_path = path_geckodriver, options=options)\n",
    "    #driver = webdriver.Firefox(executable_path = path_geckodriver, options=options)\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Get web page\n",
    "    driver.get(url_page)\n",
    "    \n",
    "    # Sleep for 15s to load feed\n",
    "    print('Waiting {} secs to let all download links load...'.format(sleep_time))\n",
    "    time.sleep(sleep_time)\n",
    "    print('-------------')\n",
    "\n",
    "    # Find elements by xpath\n",
    "    #download_elems = driver.find_elements_by_xpath((path_xpath1))\n",
    "    #print('Number of downloadable files: ', len(download_elems))\n",
    "    #print('-------------')\n",
    "    \n",
    "    # Find where two xpath strings have different entries\n",
    "    list_pos_diff = [i for i in range(len(path_xpath1)) if path_xpath1[i] != path_xpath2[i]]\n",
    "    # Get first position\n",
    "    pos_diff = list_pos_diff[0]\n",
    "\n",
    "    # Get pos of '[' \n",
    "    str_front = path_xpath1[0:pos_diff]\n",
    "    # here we use rindex to get last '['\n",
    "    pos_start = str_front.rindex('[')\n",
    "\n",
    "    # Get pos of ']' \n",
    "    str_end = path_xpath1[pos_start:]\n",
    "    pos_end = str_end.index(']')\n",
    "    # Build part 1 and part 2 of xpath\n",
    "    xpath_pt1 = path_xpath1[0:pos_start+1]\n",
    "    xpath_pt2 = path_xpath1[pos_start+pos_end:]\n",
    "\n",
    "    # Get start for range (starting value between [])\n",
    "    a = int(path_xpath1[pos_start+1:pos_start+pos_end])\n",
    "    # Get end for range (end value between [])\n",
    "    b = 1+int(path_xpath2[pos_start+1:(pos_start+pos_end+abs(len(path_xpath2)-len(path_xpath1)))])\n",
    "\n",
    "    # the range is definded from the xpath path_xpath1 to xpath path_xpath2\n",
    "    for i in range(a,b):     \n",
    "        # build xpath for loop \n",
    "        path = xpath_pt1+str(i)+xpath_pt2 \n",
    "        print(path)  \n",
    "        # use selenium webdriver to click and download\n",
    "        results = driver.find_elements_by_xpath((path))[0]\n",
    "        results.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        if i%1000==0:\n",
    "            print('Number of Downloaded files: ',i)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Sleep for 5s to ensure that everythings loaded properly\n",
    "    time.sleep(5)\n",
    "    driver.quit()\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    print('-------------')\n",
    "    print('Download sucessfull!')\n",
    "    print('{} Files downloaded to '.format(b-a)+path_download_dir)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def main():\n",
    "\n",
    "    # Paths for webscrapper\n",
    "    urlpage = 'https://geoportal.geoportal-th.de/gaialight-th/_apps/atomfeedexplorer/?#feed=http%3A//geoportal.geoportal-th.de/dienste/atom_th_gebaeude%3Ftype%3Ddataset%26id%3D97d152b8-9e00-49f3-9ae4-8bbb30873562' \n",
    "    xpath1 = '/html/body/div[2]/div/div[7]/div[2]/ul/li[1]/div[6]/div[2]/ul/li[1]/a'\n",
    "    xpath2 = '/html/body/div[2]/div/div[7]/div[2]/ul/li[1]/div[6]/div[2]/ul/li[3]/a'\n",
    "    geckodriver_dir = '/Users/Felix/Documents/Studium/PhD/05_Projects/02_Estimate_Building_Heights/preprocessing/Webscraper_Thueringen/geckodriver'\n",
    "    \n",
    "    # Path of output dir\n",
    "    download_dir = \"/Users/Felix/Desktop/test\"\n",
    "\n",
    "    # Start to webscrape\n",
    "    webscrape(urlpage,download_dir, geckodriver_dir, xpath1, xpath2,15)   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}